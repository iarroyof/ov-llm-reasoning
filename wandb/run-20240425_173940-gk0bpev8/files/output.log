Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(
Traceback (most recent call last):
  File "/home/iarroyof/Projects/ov-llm-reasoning/seq2seq_T5.py", line 207, in <module>
    #reasoning_pipeline.test(val_loader, epoch)
    ^^^^^^
  File "/home/iarroyof/Projects/ov-llm-reasoning/seq2seq_T5.py", line 205, in main
    for epoch in range(epochs): #optimizer, train_loader, epoch
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/Projects/ov-llm-reasoning/seq2seq_T5.py", line 75, in generate
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/generation/utils.py", line 1655, in generate
    result = self._beam_search(
             ^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/generation/utils.py", line 3171, in _beam_search
    outputs = self(
              ^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py", line 1742, in forward
    decoder_outputs = self.decoder(
                      ^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py", line 1109, in forward
    layer_outputs = layer_module(
                    ^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py", line 749, in forward
    hidden_states = self.layer[-1](hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py", line 338, in forward
    forwarded_states = self.DenseReluDense(forwarded_states)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/iarroyof/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt